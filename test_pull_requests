#!/usr/bin/env ruby

# Client script for submitting pull requests for testing
# as well as updating the test results from Jenkins.
#
# This script requires that the 'hub' rubygem be installed
# which provides the OAuth functionality as well as some
# other core functionality.
#
# You should be able to install 'hub' with:
#   sudo gem install hub
#
# This has to be manually run one time to establish an OAuth
# ticket.  The user setting in .test_pull_requests.json is bot_github_user

require 'rubygems'
require 'uri'
require 'hub'
require 'pp'
require 'net/https'
require 'getoptlong'
require 'time'
require 'cgi'
require 'json'

def usage
  puts <<USAGE
Usage: test_pull_requests [--help] [--merge_pull_request <pull_id>] [--local_merge_pull_request <pull_id>] [--test_pull_request <pull_id>] [--repo <repo>]

This will process all the setting specified pull requests and submit
Jenkins tests for any mergeable pull requests

Options:
-h|--help
    Show Usage info
--merge_pull_request <pull_id>
    Takes the id of the pull request to merge and merges into the branch specified by the pull request
--local_merge_pull_request <pull_id>
    Takes the id of the pull request to merge and locally merges into the branch specified by the pull request
--test_merge_pull_request <pull_id>
    Takes the id of the pull request to merge and makes sure the merge will succeed before actually merging
--mark_test_success <pull_id>
    Marks a pull request with success status for the test_settings configuration
--mark_testonlyextended_success <pull_id>
    Marks a pull request with success status for the testonlyextended_settings configuration
--merge_pretest_success
    Merges all of the pretested pull requests
--repo <repo>
    The repo of the pull request
USAGE
  exit 255
end

opts = GetoptLong.new(
["--help",               "-h",      GetoptLong::NO_ARGUMENT],
["--merge_pull_request",            GetoptLong::REQUIRED_ARGUMENT],
["--local_merge_pull_request",      GetoptLong::REQUIRED_ARGUMENT],
["--test_merge_pull_request",       GetoptLong::REQUIRED_ARGUMENT],
["--mark_test_success",             GetoptLong::REQUIRED_ARGUMENT],
["--mark_testonlyextended_success", GetoptLong::REQUIRED_ARGUMENT],
["--merge_pretest_success",         GetoptLong::NO_ARGUMENT],
["--repo",                          GetoptLong::REQUIRED_ARGUMENT],
["--config",                        GetoptLong::REQUIRED_ARGUMENT]
)

args = {}
begin
  opts.each{ |k,v| args[k[2..-1].intern]=v }
rescue GetoptLong::Error
  usage
end

if args[:help]
  usage
end

merge_pull_id = args[:merge_pull_request]
local_merge_pull_id = args[:local_merge_pull_request]
test_merge_pull_id = args[:test_merge_pull_request]
mark_test_success_pull_id = args[:mark_test_success]
mark_testonlyextended_success_pull_id = args[:mark_testonlyextended_success]
pull_id_repo = args[:repo]
config = args[:config]
merge_pretest_success = args[:merge_pretest_success]

include Hub

PROPERTIES_LOCATION = config || File.expand_path("~/.test_pull_requests.json")
Properties = if File.exists? PROPERTIES_LOCATION
  JSON.parse(IO.read(PROPERTIES_LOCATION))
else
  $stderr.puts "Properties file not found: #{PROPERTIES_LOCATION}"
  exit 255
end

# Branches and repos must be supported for all settings
$branches = []
$repos = []
Properties['settings'].values.each do |settings|
  settings['branches'].keys.each do |branch|
    $branches |= [branch]
  end
  settings['repo_to_teams'].keys.each do |repo|
    $repos |= [repo]
  end
end

$repo_to_pull_regex = {}
$repos.each do |repo|
  $repo_to_pull_regex[repo] = /https:\/\/github.com\/#{Properties['github_user']}\/#{repo}\/(pulls?|issues?)\/(\d+)/
end

$permissions = {}
$commits = {}
$submitted_tests = {}
$branches.each do |branch|
  $submitted_tests[branch] = {}
end

ACTION_PREFIX               = Properties['action_required_prefix']
ACTION_NOT_MERGE            = "#{ACTION_PREFIX} Pull request cannot be automatically merged, please rebase your branch from latest HEAD and push again"
ACTION_NOT_TEAM             = "#{ACTION_PREFIX} Please contact #{Properties['irc_channel']} to have this pull request manually reviewed and tested"
ACTION_UNSUPPORTED_BRANCH   = "#{ACTION_PREFIX} Only pull request(s) from #{$branches.pretty_inspect.chomp} are handled by the #{Properties['bot_github_user']}"
NEEDS_REBASE_LABEL          = "needs-rebase"

# flake_denied_prefix returns the prefix to be used for the flake info comment for a particular job
def flake_denied_prefix(repo, job)
  "The #{Properties['repo_to_product'][repo]} #{job} job could not be run again for this pull request."
end

GITHUB_API_BASE_URL = 'https://api.github.com'
GITHUB_BASE_URL = 'https://github.com'

# We use a saturating counter to get a more stable reading of mergeability from
# the GitHub API for a pull request. The following two values are the rails at
# which we saturate.
NOT_MERGEABLE = 10
MERGEABLE = 0

def evaluated_marker(repo, settings)
  "Evaluated for #{Properties['repo_to_product'][repo].downcase} #{settings['name']} up to %s"
end

def evaluated_marker_regex(repo, settings)
  /^Evaluated for #{Properties['repo_to_product'][repo].downcase} #{settings['name']} up to (.*)/
end

def branch_settings(branch, settings)
  s = nil
  if settings['branches'][branch]
    s = settings['branches'][branch]
  elsif settings['branches']['*']
    s = settings['branches']['*']
  end
  s
end

def submitted_tests_for_branch(branch)
  $submitted_tests[branch] ? $submitted_tests[branch] : $submitted_tests['*']
end

# We do not expect the groups used to define trusted and administrative
# members for this repo to change often, so we will 'cache' the group ID
# to GitHub name and URL for them in a file on disk.
TEAM_CACHE_LOCATION = File.expand_path("~/.team_cache.json")
$team_cache = if File.exists? TEAM_CACHE_LOCATION
  JSON.parse(IO.read(TEAM_CACHE_LOCATION))
else
  {}
end

# Dynamically extend GitHubAPI to add methods that don't
# require a local git project
module Hub
  class GitHubAPI

    # team_url_and_name returns the user-friendly URL and name for a GitHub team.
    # If the team ID is found in the $team_cache, we will simply use it. If it
    # is not, however, we will need to expend an API request to list all of the
    # teams we care about and fill in the $team_cache before continuing.
    def team_url_and_name(team_id)
      # We want to return our cached data whenever we have it, but we also want
      # to refresh our cache once in a while, so with a 1% chance we will ignore
      # data in our cache and re-list anyway.
      if !$team_cache.has_key?(team_id) || (rand(100) == 1)
        res = get "#{GITHUB_API_BASE_URL}/orgs/#{Properties['github_user']}/teams"
        if res.success?
          res.data.each do |team_info|
            # The GitHub team object doesn't list its own URL, but we can construct
            # it using the 'slug' and the organization name
            team_url = "#{GITHUB_BASE_URL}/orgs/#{Properties['github_user']}/teams/#{team_info['slug']}"
            $team_cache[team_info['id']] = { 'url' => team_url, 'name' => team_info['name']}
          end
          # If we just filled out the cache, we should write it to disk so
          # the next test-pull-requests run can save itself the API call
          IO.write(TEAM_CACHE_LOCATION, JSON::JSON.pretty_generate($team_cache))
          $stderr.puts "  Wrote a cache of team ID to URL and proper name at #{TEAM_CACHE_LOCATION}"
        else
          $stderr.puts res.body
          res.error!
        end
      end
      [$team_cache[team_id]['url'], $team_cache[team_id]['name']]
    end

    def list_pull_requests(repo, num_tries=3)
      pull_requests = []
      page = 1
      last_pull_requests = nil
      while (!last_pull_requests || last_pull_requests.length == 100)
        (1..num_tries).each do |i|
          res = get "#{GITHUB_API_BASE_URL}/repos/#{Properties['github_user']}/#{repo}/pulls?page=#{page}&per_page=100"
          rate_limit_remaining = res.header['X-RateLimit-Remaining']
          $stderr.puts "Rate limit remaining: #{rate_limit_remaining}"
          if rate_limit_remaining && rate_limit_remaining.to_i < 500
            $stderr.puts "WARNING: Skipping processing due to rate limit approaching!"
            exit 0
          end
          if res.success?
            last_pull_requests = res.data
            pull_requests += last_pull_requests
            page += 1
            break
          elsif i == num_tries
            $stderr.puts res.body
            res.error!
          end
        end
      end
      pull_requests
    end

    def get_pull_request(id, repo, num_tries=1)
      (1..num_tries).each do |i|
        res = get "#{GITHUB_API_BASE_URL}/repos/#{Properties['github_user']}/#{repo}/pulls/%s" % id
        if res.success?
          return res.data
        elsif i == num_tries
          res.error!
        else
          sleep 1
        end
      end
    end

    # is_mergeable? is a more stable way of determining if a pull request is mergeable than
    # probing the pull request object as `pull_request["mergeable"]`. It seems like our first
    # request for the mergeable status may trigger a re-calculation, so if that is the case,
    # we will re-try the request a couple of times to get the correct status
    #
    # The GitHub API will return one of three states for pull_request[mergeable]:
    #  - true, if the pull request has been evaluated and found not to have merge conflicts
    #  - false, if the pull request has been evaluated and found to have merge conflicts
    #  - null, if the pull request has not yet been evaluated and the status is unknown
    # In the third case, we will defer to the pull_request[mergeable_state], which gives
    # a further breakdown of states to determine if we will be testing this pull request.
    # We try three times and exit early if we get a positive result as we would like to err
    # on the side of running a test (and it quickly failing due to merge conflicts) rather
    # than not running a set of tests on a valid pull request.
    def is_mergeable?(id, repo, num_tries=3)
      (1..num_tries).each do |i|
        pull_request = get_pull_request(id, repo, num_tries)
        mergeable = pull_request['mergeable']
        # Mergeable has become unreliable.  Resort to mergeable state for now if nil.
        # TODO: Re-evaluate this at a later date
        if mergeable.nil?
          case pull_request['mergeable_state']
          when 'checking', 'dirty', 'unstable'
            mergeable = false
          when 'unknown', 'clean', 'stable'
            mergeable = !pull_request['merged']
          end
        end
        return true if mergeable
        sleep 1 if i > 1 && i < num_tries
      end
      return false
    end

    # get_last_commit returns the most recent commit in the branch the pull request originates from
    def get_last_commit(id, repo, num_tries=3)
      commits = nil
      if $commits[repo]
        commits = $commits[repo][id]
      else
        $commits[repo] = {}
      end
      unless commits
        (1..num_tries).each do |i|
          res = get "#{GITHUB_API_BASE_URL}/repos/#{Properties['github_user']}/#{repo}/pulls/%s/commits?per_page=100" % id
          if res.success?
            commits = res.data
            $commits[repo][id] = commits
            break
          elsif i == num_tries
            res.error!
          end
        end
      end
      commits.last
    end

    def get_comments(issue_id, repo, num_tries=3)
      page = 1
      comments = []
      last_comments = nil
      while (!last_comments || last_comments.length == 100)
        (1..num_tries).each do |i|
          res = get "#{GITHUB_API_BASE_URL}/repos/#{Properties['github_user']}/#{repo}/issues/%s/comments?page=#{page}&per_page=100" % issue_id
          if res.success?
            last_comments = res.data
            comments += last_comments
            page += 1
            break
          end
          res.error! if i == num_tries
        end
      end
      comments
    end

    def delete_comment(comment_id, repo, num_tries=3)
      $stderr.puts "  Deleting comment ##{comment_id}"
      (1..num_tries).each do |i|
        res = delete "#{GITHUB_API_BASE_URL}/repos/#{Properties['github_user']}/#{repo}/issues/comments/%s" % [comment_id]
        # If we get 404 on a retry, that means there's no comment to delete
        break if res.success? || (res.code == '404' && i > 1)
        res.error! if i == num_tries
      end
    end

    def add_comment(issue_id, repo, comment, num_tries=3)
      params = { :body => comment }
      (1..num_tries).each do |i|
        res = post "#{GITHUB_API_BASE_URL}/repos/#{Properties['github_user']}/#{repo}/issues/%s/comments" % [issue_id], params
        return res.data if res.success?
        res.error! if i == num_tries
      end
    end

    def update_comment(comment_id, repo, comment, num_tries=3)
      $stderr.puts "  Updating comment ##{comment_id} with #{comment}"
      params = { :body => comment }
      (1..num_tries).each do |i|
        res = post "#{GITHUB_API_BASE_URL}/repos/#{Properties['github_user']}/#{repo}/issues/comments/%s" % [comment_id], params
        return res.data if res.success?
        res.error! if i == num_tries
      end
    end

    def recreate_comment(issue_id, comment_id, repo, comment)
      $stderr.puts "  Recreating comment ##{comment_id} with #{comment}"
      delete_comment(comment_id, repo)
      add_comment(issue_id, repo, comment)
    end

    def ensure_labels(issue_id, repo, labels, num_tries=3)
      existing_labels = get_labels(issue_id, repo, num_tries)
      existing_labels = existing_labels.map{|label| label['name']}
      missing_labels = labels - existing_labels
      if missing_labels.length > 0
        add_labels(issue_id, repo, missing_labels, num_tries)
      end
    end

    def add_labels(issue_id, repo, labels, num_tries=3)
      $stderr.puts "  Adding labels: #{labels.join(',')}"
      (1..num_tries).each do |i|
        res = post "#{GITHUB_API_BASE_URL}/repos/#{Properties['github_user']}/#{repo}/issues/%s/labels" % [issue_id], labels
        return res.data if res.success?
        res.error! if i == num_tries
      end
    end

    def remove_labels(issue_id, repo, labels, num_tries=3)
      existing_labels = get_labels(issue_id, repo, num_tries)
      existing_labels = existing_labels.map{|label| label['name']}
      labels = labels & existing_labels
      labels.each do |label|
        remove_label(issue_id, repo, label, num_tries)
      end
    end

    def remove_label(issue_id, repo, label, num_tries=3)
      $stderr.puts "  Removing label #{label}"
      (1..num_tries).each do |i|
        res = delete "#{GITHUB_API_BASE_URL}/repos/#{Properties['github_user']}/#{repo}/issues/%s/labels/%s" % [issue_id, label]
        break if res.success?
        res.error! if i == num_tries
      end
    end

    def get_labels(issue_id, repo, num_tries=3)
      page = 1
      labels = []
      last_labels = nil
      while (!last_labels || last_labels.length == 100)
        (1..num_tries).each do |i|
          res = get "#{GITHUB_API_BASE_URL}/repos/#{Properties['github_user']}/#{repo}/issues/%s/labels?page=#{page}&per_page=100" % issue_id
          if res.success?
            last_labels = res.data
            labels += last_labels
            page += 1
            break
          end
          res.error! if i == num_tries && res.code != '404'
        end
      end
      labels
    end

    def update_status(context, sha, repo, state, url, desc, num_tries=3)
      $stderr.puts "  Updating status of '#{sha}' with state: #{state}"
      params = { :state => state, :target_url => url, :description => desc, :context => context}
      (1..num_tries).each do |i|
        res = post "#{GITHUB_API_BASE_URL}/repos/#{Properties['github_user']}/#{repo}/statuses/%s" % [sha], params
        return res.data if res.success?
        #res.error! if i == num_tries
      end
    end

    def get_last_status(context, sha, repo, num_tries=3)
      (1..num_tries).each do |i|
        res = get "#{GITHUB_API_BASE_URL}/repos/#{Properties['github_user']}/#{repo}/commits/#{sha}/statuses?per_page=100"
        if res.success?
          last_status = nil
          res.data.each do |status|
            if status['context'] == context
              last_status = status
              break
            end
          end
          return last_status
        end
        res.error! if i == num_tries
      end
    end

    # user_trusted? determines if the user is part of a trusted team in the repository
    def user_trusted?(login, repo, settings)
      user_in_group?(login, repo, settings, 'repo_to_teams')
    end

    # user_admin? determines if the user is part of a administrative team in the repository
    def user_admin?(login, repo, settings)
      user_in_group?(login, repo, settings, 'repo_to_admin_teams')
    end

    # user_in_group? determines if the user is part of a team in the repository, where
    # the group of team members is specified by a group identifier
    def user_in_group?(login, repo, settings, group_identifier)
      trusted = false
      repo_setting_key = "#{repo}_#{settings['name']}_#{group_identifier}"
      if $permissions[login]
        if $permissions[login][repo_setting_key]
          trusted = $permissions[login][repo_setting_key] ? true : false
        end
      else
        $permissions[login] = {}
      end
      if $permissions[login][repo_setting_key].nil?
        settings[group_identifier][repo].each do |team|
          res = get "#{GITHUB_API_BASE_URL}/teams/#{team}/members/#{login}"
          trusted = res.success?
          break if trusted
        end
        $permissions[login][repo_setting_key] = trusted
      end
      trusted
    end

    # Submit tests to Jenkins and update the comment
    def submit_tests(repo_to_pull_request, base_repo, branch, pull_id, comment_id, extended_tests, settings)
      submitted_tests = submitted_tests_for_branch(branch)
      unless settings['allow_multiple']
        if submitted_tests[settings['name']] || JenkinsAPI.previous_build_running?(branch, settings, base_repo)
          submitted_tests[settings['name']] = true
          $stderr.puts "  Waiting for existing build to finish"
          return
        end
      end

      # If the project is stable, submit the tests
      build_url = JenkinsAPI.submit_jenkins_job(repo_to_pull_request, branch, extended_tests, settings)

      running_comment = "#{settings['test_prefix']} Running (#{build_url})"
      running_comment += " (Extended Tests: #{extended_tests.join(', ')})" unless extended_tests.empty?

      # Update the comments to reflect the new tests running
      recreate_comment(pull_id, comment_id, base_repo, running_comment)

      repo_to_pull_request.each do |repo, pull_request|
        if repo != base_repo
          process_or_create_comment(pull_request['number'], repo, settings) do |c_id, comment, comment_updated_at|
            update_comment(c_id, repo, running_comment)
          end
        end
        commit = get_last_commit(pull_request['number'], repo)
        update_status(settings['test_prefix'], commit['sha'], repo, 'pending', build_url, 'Testing')
      end

      submitted_tests[settings['name']] = true unless settings['allow_multiple']
    end

    def mark_test_success(pull_id, repo, settings)
      $stderr.puts "  Marking SUCCESS for pull request ##{pull_id} in repo '#{repo}'"
      bot_comment = get_comment_with_prefix(pull_id, repo, settings['test_prefix'])
      build_url = nil
      extended_tests = nil
      if bot_comment['body'] =~ /^#{settings['test_prefix']} Running \(([^\)]+)\)( \(Extended Tests: [^\)]+\).*)?/
        build_url = $1
        extended_tests = $2
      else
        raise "'#{settings['name']}' pull request not found"
      end
      comment = "#{settings['test_prefix']} SUCCESS (#{build_url})"
      comment += extended_tests if extended_tests
      recreate_comment(pull_id, bot_comment['id'], repo, comment)

      commit = get_last_commit(pull_id, repo)
      update_status(settings['test_prefix'], commit['sha'], repo, 'success', build_url, 'Passed')
    end

    def merge_pull_request(pull_id, repo, settings, merge_pretest_success_url=nil)
      $stderr.puts "  Merging pull request ##{pull_id} for repo '#{repo}'"
      pull_request, bot_comment, comments = test_merge_pull_request(pull_id, repo, settings)
      build_url = nil
      if merge_pretest_success_url
        build_url = merge_pretest_success_url
      elsif bot_comment['body'] =~ /^#{settings['test_prefix']} Running \((.*)\)/
        build_url = $1
      else
        raise "'#{settings['name']}' pull request not found"
      end
      comment = "#{settings['test_prefix']} SUCCESS (#{build_url})"
      begin
        branch = pull_request['base']['ref']
        b_settings = branch_settings(branch, settings)
        image_base_name = b_settings['image_base_name']
        if image_base_name
          image_base_name.gsub!('*', branch)
          image = "#{image_base_name}_#{JenkinsAPI.get_next_build(branch, settings, b_settings['downstream_job_name'])}"
          comment = "#{comment} (Image: #{image})"
        end
      rescue Exception => e
        $stderr.puts e.message
      end

      commit = get_last_commit(pull_request['number'], repo)
      update_status(settings['test_prefix'], commit['sha'], repo, 'success', build_url, 'Passed')
      sleep 10
      params = { :commit_message => "Merged by #{Properties['bot_github_user']}" }
      sleep_time = 1
      res = nil
      num_tries = 5
      (1..num_tries).each do |i|
        res = put "#{GITHUB_API_BASE_URL}/repos/#{Properties['github_user']}/#{repo}/pulls/#{pull_id}/merge", params
        break if res.success?
        if i < num_tries
          sleep sleep_time
          sleep_time *= 2
          $stderr.puts "  Retrying...  attempt: #{i+1}"
        end
      end

      res.error! unless res.success?

      update_comment(bot_comment['id'], repo, comment)

      if settings['trello_card_refs']
        settings['trello_card_refs'].each do |ref|
          values = get_values_from_pull_request(pull_id, repo, /(#{ref}_\d+)/i, pull_request, comments)
          values.each do |value|
            comment = "A pull request referencing this card has been merged: #{GITHUB_BASE_URL}/#{Properties['github_user']}/#{repo}/pull/#{pull_id}"
            $stderr.puts `trello comment '#{comment}' --card-ref #{value}`
          end
        end
        values = get_values_from_pull_request(pull_id, repo, /(https?:\/\/trello\.com\/c\/[[:alnum:]]+)/, pull_request, comments)
        values.each do |value|
          comment = "A pull request referencing this card has been merged: #{GITHUB_BASE_URL}/#{Properties['github_user']}/#{repo}/pull/#{pull_id}"
          $stderr.puts `trello comment '#{comment}' --card-url '#{value}'`
        end
      end
    end

    def test_merge_pull_request(pull_id, repo, settings)
      $stderr.puts "  Test merging pull request ##{pull_id} for repo '#{repo}'"
      comments = get_comments(pull_id, repo)
      bot_comment = get_comment_with_prefix(pull_id, repo, settings['test_prefix'], comments)
      raise "Missing '#{settings['test_prefix']}' comment!" if bot_comment.nil?
      evaluated_time = get_evaluated_time(comments, repo, settings)
      raise "Missing evaluated flag!" if evaluated_time.nil?
      pull_request = get_pull_request(pull_id, repo, 10)
      raise "Pull request isn't open!" unless pull_request['state'] == 'open'
      mergeable = pull_request['mergeable']
      # This call isn't reliable so make sure
      mergeable = is_mergeable?(pull_id, repo, 10) unless mergeable
      raise "Pull request isn't mergeable!" unless mergeable
      pull_request_updated_at, pull_request_changed_after_eval = get_updated_at(pull_request, comments, settings)
      unless !pull_request_changed_after_eval
        $stderr.puts "  Evaluated time: #{evaluated_time}"
        $stderr.puts "  Updated at: #{pull_request_updated_at}"
        raise "Pull request was updated after testing started!"
      end
      return pull_request, bot_comment, comments
    end

    def local_merge_pull_request(pull_id, repo)
      $stderr.puts "Local merging pull request ##{pull_id} for repo '#{repo}'"
      pull_request = get_pull_request(pull_id, repo, 10)
      merge_command = %{
set -ex
pushd #{repo}
  git checkout #{pull_request['base']['ref']}
  git checkout -b tpr_#{pull_request['head']['ref']}_#{pull_request['user']['login']}
  git pull #{pull_request['head']['repo']['ssh_url']} #{pull_request['head']['ref']}
  git pull #{pull_request['head']['repo']['ssh_url']} #{pull_request['head']['ref']} --tags
  git checkout #{pull_request['base']['ref']}
  git merge tpr_#{pull_request['head']['ref']}_#{pull_request['user']['login']}
  git submodule update --recursive
popd
}
      output = `#{merge_command}`
      exit_code = $?.exitstatus
      puts output
      exit 1 if exit_code != 0
    end

    def put url, params = nil
      perform_request url, :Put do |req|
        if params
          req.body = JSON.dump params
          req['Content-Type'] = 'application/json;charset=utf-8'
        end
        req['User-Agent'] = Properties['bot_github_user']
        yield req if block_given?
        req['Content-Length'] = req.body ? req.body.length : 0
      end
    end

    def post url, params = nil
      perform_request url, :Post do |req|
        if params
          req.body = JSON.dump params
          req['Content-Type'] = 'application/json;charset=utf-8'
          req['User-Agent'] = Properties['bot_github_user']
        end
        yield req if block_given?
        req['Content-Length'] = req.body ? req.body.length : 0
      end
    end

    def perform_request url, type
      url = URI.parse url unless url.respond_to? :host

      require 'net/https'
      req = Net::HTTP.const_get(type).new request_uri(url)
      req['User-Agent'] = Properties['bot_github_user']

      http = configure_connection(req, url) do |host_url|
        create_connection host_url
      end

      apply_authentication(req, url)
      yield req if block_given?

      begin
        res = http.start { http.request(req) }
        res.extend ResponseMethods
        return res
      rescue SocketError => err
        raise Context::FatalError, "error with #{type.to_s.upcase} #{url} (#{err.message})"
      end
    end


    def delete url
      perform_request url, :Delete do |req|
        req['User-Agent'] = Properties['bot_github_user']
        yield req if block_given?
      end
    end

    # process_or_create_comment yields the comment body and metadata for the last bot
    # comment for a particular pull request. If no comment exists at the time this is
    # called, a place-holder comment is made to initialize the pull request analysis
    # process
    def process_or_create_comment(issue_id, repo, settings, comments=nil)
      bot_comment = get_comment_with_prefix(issue_id, repo, settings['test_prefix'], comments)

      unless bot_comment
        # In the process of evaluating a pull request, we could have called this method
        # previously and, since we're not updating our internal cache of comments, the
        # comments array, we could have stale data in that cache, so we want to force
        # get_comment_with_prefix to fetch a new list of comments to make sure we find
        # a bot comment if it exists but we don't have it cached
        bot_comment = get_comment_with_prefix(issue_id, repo, settings['test_prefix'])
        unless bot_comment
          # No comment found, create a new one and yield to it
          $stderr.puts "  Creating placeholder comment"
          evaluating_comment = "#{settings['test_prefix']} Evaluating for testing"
          bot_comment = add_comment(issue_id, repo, evaluating_comment)
        end
      end

      yield bot_comment['id'], bot_comment['body'], Time.parse(bot_comment['updated_at'])
    end

    # create_or_update_comment tries to update the previous bot comment with the given
    # prefix to contain the new comment body, or, if there is no previous bot comment
    # with the given prefix, tries to create a new bot comment instead
    def create_or_update_comment(issue_id, repo, comment_prefix, comment, comments=nil)
      bot_comment = get_comment_with_prefix(issue_id, repo, comment_prefix, comments)

      if bot_comment
        update_comment(bot_comment['id'], repo, comment) if bot_comment['body'] != comment
      else
        # No comment found, create a new one
        add_comment(issue_id, repo, comment)
      end

    end

    #
    # Creates or updates a comment with given prefix
    #
    def delete_comment_with_prefix(issue_id, repo, comment_prefix, comments=nil)
      comment = get_comment_with_prefix(issue_id, repo, comment_prefix, comments)
      if comment && comments
        comments.delete_if { |c| c['id'] == comment['id'] }
      end
      delete_comment(comment['id'], repo) if comment
      return comment
    end

    # get_comment_with_prefix returns a comment authored by the bot with the given prefix, if one exists.
    # In order to ensure that we don't return a comment that starts with a longer prefix that aliases the
    # prefix we're passed, the regex we use requires a word boundary anchor, whitespace character or line
    # end at the end of the prefix we're passed.
    def get_comment_with_prefix(issue_id, repo, comment_prefix, comments=nil)
      prefix_comment = nil

      comments = comments ? comments : get_comments(issue_id, repo)

      comments.each do |comment|
        if comment['body'] =~ /^#{Regexp.quote(comment_prefix)}(\b|$|\s)/ && (comment['user']['login'] == Properties['bot_github_user'])
          prefix_comment = comment
          break
        end
      end

      prefix_comment
    end

    #
    # Gets a comment with given prefix
    #
    def recreate_comment_with_prefix(issue_id, repo, comment_prefix, comment, comments=nil)
      comments = get_comments(issue_id, repo) if comments.nil?
      delete_comment_with_prefix(issue_id, repo, comment_prefix, comments)
      create_or_update_comment(issue_id, repo, comment_prefix, comment, comments)
    end

    def get_comment_with_value(issue_id, repo, value, comments=nil)
      comment = nil

      comments = comments ? comments : get_comments(issue_id, repo)

      # See if we can find an existing bot comment
      comments.each do |c|
        if c['body'] == value && (c['user']['login'] == Properties['bot_github_user'])
          comment = c
          break
        end
      end

      comment
    end

    def get_values_from_pull_request(issue_id, repo, value_regex, pull_request, comments=nil)
      values = []

      comments = comments ? comments : get_comments(issue_id, repo)

      add_values_by_regex(pull_request['title'], value_regex, values)
      add_values_by_regex(pull_request['body'], value_regex, values)

      comments.each do |c|
        add_values_by_regex(c['body'], value_regex, values)
      end
      values.uniq!
      values
    end

    def add_values_by_regex(content, value_regex, values)
      if content
        index = 0
        while index do
          index = content.index(value_regex, index)
          if index
            value = $1
            index += value.length
            values << value
          end
        end
      end
    end

    # get_evaluated_time returns the time at which the bot last evaluated this pull request,
    # or returns nil if the bot never evaluated the pull request at all
    def get_evaluated_time(comments, repo, settings)
      comments = sort_comments(comments)

      comments.each do |comment|
        if comment['user']['login'] == Properties['bot_github_user'] && comment['body'] =~ evaluated_marker_regex(repo, settings)
          return Time.parse(comment['updated_at'])
        end
      end
      return nil
    end

    # get_trusted_trigger_time returns the time at which the last trusted user added a trigger,
    # as best as we can tell. This will not always be able to determine the exact trigger time.
    def get_trusted_trigger_time(pull_request, comments, settings)
      trigger_time_for_user_in_group(pull_request, comments, settings, 'repo_to_teams')
    end

    # get_admin_trigger_time returns the time at which the last administrative user added a trigger,
    # as best as we can tell. This will not always be able to determine the exact trigger time.
    def get_admin_trigger_time(pull_request, comments, settings)
      trigger_time_for_user_in_group(pull_request, comments, settings, 'repo_to_admin_teams')
    end

    # trigger_time_for_user_in_group returns the time at which the last trigger was added to the pull
    # request by a user in the group identified with the group identifier. This function will return
    # the time of the last trigger as best as we can tell, and will not always be able to determine
    # the exact trigger time.
    def trigger_time_for_user_in_group(pull_request, comments, settings, group_identifier)
      login = pull_request['user']['login']
      updated_at, _ = get_updated_at(pull_request, comments, settings)
      repo = pull_request['base']['repo']['name']

      trigger_regex = /\[#{settings['name']}\]/i
      trigger_time = nil
      trigger_login = nil
      if pull_request['title'] =~ trigger_regex || pull_request['body'] =~ trigger_regex
        if user_in_group?(login, repo, settings, group_identifier)
          # Once we determine that the grouped user has a trigger statement in their pull
          # request title or body, we need to determine what time we will claim the
          # trigger was added. We can't use the created_at time, since the user could
          # edit their title or body to add the trigger, and we can't use the updated_at
          # time, since *any* action on the pull request will update that time. So,
          # we prefer to use the last time that the bot evaluated the pull request, and,
          # if the bot has never evaluated the pull request, we use the updated_at time.
          evaluated_time = get_evaluated_time(comments, repo, settings)
          trigger_time = evaluated_time || Time.parse(pull_request['updated_at'])
          trigger_login = login
        end
      end

      comments = sort_comments(comments)

      # Even if a trigger statement was found in the pull request body or title,
      # a more recent trigger could exist in the comments, and we want to ensure
      # that we return the most recent trigger time
      comments.each do |comment|
        if comment['body'] =~ trigger_regex
          comment_login = comment['user']['login']
          if user_in_group?(comment_login, repo, settings, group_identifier)
            trigger_comment_updated_at = Time.parse(comment['updated_at'])
            # If we find a trigger phrase from a grouped user in a comment, we will use
            # the time that their comment was made as the trigger time if and only if
            # the user posted their trigger phrase after the last commit was created,
            # ensuring that the grouped user has signed off on all of the commits to be
            # tested
            if user_in_group?(login, repo, settings, group_identifier) || trigger_comment_updated_at > updated_at
              # Furthermore, we only want to update the trigger time if we have a more
              # recent time from the grouped user's comment than the time we got by
              # investigating the pull request body and title
              if !trigger_time || trigger_comment_updated_at > trigger_time
                trigger_time = trigger_comment_updated_at
                trigger_login = comment_login
              end
              break
            end
          end
        end
      end
      return [trigger_time, trigger_login]
    end

    def get_extended_tests(pull_request, comments, branch, settings)
      extended_tests = []
      if settings['allow_multiple'] && branch_settings(branch, settings)['extended_tests_param']
        extended_regex = /\[extended *:( *[^,\[\]]+ *(, *[^,\[\]]+ *)*)\]/i
        if pull_request['title'] =~ extended_regex
          extended_tests += $1.split(',')
        end

        if pull_request['body'] =~ extended_regex
          extended_tests += $1.split(',')
        end

        comments.each do |comment|
          if comment['body'] =~ extended_regex
            extended_tests += $1.split(',')
          end
        end
        extended_tests.each do |test|
          test.strip!
        end
        extended_tests.uniq!
      end
      return extended_tests
    end

    # sort_comments sorts an array of comments by the time
    # they were last updated, most recently updated first
    def sort_comments(comments)
      comments = comments.sort_by do |comment|
        Time.parse(comment['updated_at'])
      end
      comments.reverse!
      comments
    end

    # update_evaluated_markers should be called after it is known that the Jenkins job should
    # be triggered for this pull request. evaluate_updated_markers updates the GitHub bot's
    # `evaluated` comment to reflect the fact that we have now evaluated the pull request again.
    # If the pull request was previously waiting for a stable downstream build or in the build
    # queue, we add a comment to reflect that we are re-calculating the build queue position.
    def update_evaluated_markers(repo_to_pull_request, trigger_updated_at, settings)
      repo_to_pull_request.each do |repo, pull_request|
        pull_request_comments = get_comments(pull_request['number'], repo)
        test_prefix_comment = get_comment_with_prefix(pull_request['number'], repo, settings['test_prefix'], pull_request_comments)
        if !test_prefix_comment || !(test_prefix_comment['body'] =~ /^#{settings['test_prefix']} Waiting/)
          being_queued_comment = "#{settings['test_prefix']} Waiting: Determining build queue position"
          create_or_update_comment(pull_request['number'], repo, settings['test_prefix'], being_queued_comment, pull_request_comments)
        end
        pull_request_evaluated_time = get_evaluated_time(pull_request_comments, repo, settings)
        _, pull_request_changed_after_eval = get_updated_at(pull_request, pull_request_comments, settings)
        if pull_request_changed_after_eval || pull_request_evaluated_time < trigger_updated_at
          commit = get_last_commit(pull_request['number'], repo)
          # Add a new evaluated marker
          add_comment(pull_request['number'], repo, (evaluated_marker(repo, settings) % commit['sha']))
          # Delete the old evaluated markers
          pull_request_comments.each do |comment|
            if comment['user']['login'] == Properties['bot_github_user'] && comment['body'] =~ evaluated_marker_regex(repo, settings)
              delete_comment(comment['id'], repo)
            end
          end
        end
      end
    end

    # get_updated_at returns the time at which the last commit on the pull request was created, and
    # whether or not the pull request has been updated since the last time the bot saw it, determined by
    # looking at the commit referenced in the last evaluated comment and comparing the latest commit SHA
    def get_updated_at(pull_request, comments, settings)
      updated_at = nil
      comments = sort_comments(comments)
      previous_sha = nil
      comments.each do |comment|
        if comment['user']['login'] == Properties['bot_github_user'] && comment['body'] =~ evaluated_marker_regex(pull_request['base']['repo']['name'], settings)
          previous_sha = $1
        end
      end
      commit = get_last_commit(pull_request['number'], pull_request['base']['repo']['name'])

      updated_at = Time.parse(commit['commit']['committer']['date'])
      changed_after_last_evaluation = commit['sha'] != previous_sha

      [updated_at, changed_after_last_evaluation]
    end

    # add_coreq adds a co-requisite pull request to the repo_to_pull_request mapping if the co-requisite statement
    # is trusted and the co-requisite pull request is merge-able.
    def add_coreq(addtl_pull_id, addtl_pull_repo, login, trigger_login, repo_to_pull_request, settings, trigger_updated_at, updated_at, base_pull_id, base_repo, comments)
      $stderr.puts "  Processing dependency on pull request #{addtl_pull_id} in repo '#{addtl_pull_repo}'"
      # We can add the co-requisite if the author of the original pull request is trusted, or if the author of the trigger
      # statement is trusted and they authored the trigger statement after the co-requisite statement was made
      author_trusted = user_trusted?(login, addtl_pull_repo, settings)
      trigger_author_trusted = user_trusted?(trigger_login, addtl_pull_repo, settings)
      if author_trusted || (trigger_author_trusted && (trigger_updated_at && trigger_updated_at >= updated_at))
        pull_request = get_pull_request(addtl_pull_id, addtl_pull_repo, 2)
        if pull_request
          # On co-requisite pull requests, we do not expect there to be trigger statements, as the
          # triggers on the parent pull request will trigger builds and tests with the co-requisites
          # therefore, we need to manage the mergeable state of the co-requisite pull requests here
          # while we're considering them for their parent
          if pull_request['mergeable']
            repo_to_pull_request[addtl_pull_repo] = pull_request
            set_mergeable(addtl_pull_id, addtl_pull_repo, pull_request['user']['login'])
          # Do nothing if the PR has been merged
          elsif !(pull_request['merged'])
            if set_not_mergeable(addtl_pull_id, addtl_pull_repo, pull_request['user']['login']) >= NOT_MERGEABLE
              comment = "Linked pull request #{addtl_pull_id} in repo '#{addtl_pull_repo}' is not mergeable"
              $stderr.puts "  #{comment}"
              add_comment(base_pull_id, base_repo, comment) unless get_comment_with_value(base_pull_id, base_repo, comment, comments)
            end
          end
        else
          comment = "Linked pull request #{addtl_pull_id} in repo '#{addtl_pull_repo}' not found"
          $stderr.puts "  #{comment}"
          add_comment(base_pull_id, base_repo, comment) unless get_comment_with_value(base_pull_id, base_repo, comment, comments)
        end
      else
        comment = "User '#{login}' is not permitted to #{settings['name']} linked pull request #{addtl_pull_id} in '#{addtl_pull_repo}'.  If the #{settings['name']} was requested by another user with permission to #{settings['name']} in '#{addtl_pull_repo}', the linked pull request must be in a comment before the #{settings['name']} comment (not including the pull request description) or be added by a user with permission to #{settings['name']} in '#{addtl_pull_repo}'."
        $stderr.puts "  #{comment}"
        add_comment(base_pull_id, base_repo, comment) unless get_comment_with_value(base_pull_id, base_repo, comment, comments)
      end
    end

    # comments_after returns all of the comments in the given list that were updated
    # after the given time
    def comments_after(comments, time)
      valid_comments = []
      comments.each do |comment|
        if Time.parse(comment['updated_at']) > time
          valid_comments << comment
        end
      end

      valid_comments
    end

    # has_valid_flake_comment? determines if a valid flake explanation comment exists
    #
    # A flake comment is valid iff at least one given issue link in the comment:
    #    - resides in the correct repository
    #    - points to issues with the correct label
    def has_valid_flake_comment?(comments, flake_config)
      general_issue_spec = /(https?:\/\/github.com\/.*\/issues\/[0-9]+)/
      general_ref_spec = /(^|\s)#(\d+)/

      $stderr.puts "  Searching comments for a flake identification comment..."
      comments.each do |comment|
        body = comment['body']

        # we want to allow users to link to issues using full URLs or the
        # short-hand #1234 GitHub issue references
        comment_contains_issue = body =~ general_issue_spec || body =~ general_ref_spec
        # we can't allow the bot to be a valid author, or we would pick up
        # comments where the bot explains the flake syntax to GitHub users
        comment_author_valid = comment['user']['login'] != Properties['bot_github_user']

        if comment_contains_issue && comment_author_valid
          $stderr.puts "  Investigating comment by #{comment['user']['login']}: #{comment['html_url']}"
          has_valid_issue_link = has_valid_issue_link?(body, general_issue_spec, Properties['github_user'], flake_config)
          has_valid_issue_ref = has_valid_issue_ref?(body, general_ref_spec, flake_config)

          return true if has_valid_issue_ref || has_valid_issue_link
        end
      end

      return false
    end

    # has_valid_issue_link? validates that the comment's issue list contains
    # at least one valid flake issue.
    # We need to validate that the links we found with the general spec are
    # from the correct organization/owner and in the correct repository
    def has_valid_issue_link?(body, general_issue_spec, org, flake_config)
      body.scan(general_issue_spec) do |issue|
        $stderr.puts "      Determining if issue #{issue[0]} meets criteria..."
        if issue[0] =~ /https?:\/\/github.com\/#{Regexp.quote(org)}\/#{Regexp.quote(flake_config['repo'])}\/issues\/([0-9]+)/
          issue_id = $1.to_i
          if issue_has_label?(issue_id, flake_config['repo'], flake_config['label'])
            $stderr.puts "      Issue #{issue[0]} is a valid flake issue"
            return true
          end
        end
      end

      return false
    end

    # has_valid_issue_ref? validates that the comment's ref list contains
    # at least one valid flake reference.
    # GitHub issue references will always link to the same org/repo that
    # the comment containing the reference is posted in, so we only need
    # to validate that the ref is to an issue with the correct label
    def has_valid_issue_ref?(body, general_ref_spec, flake_config)
      body.scan(general_ref_spec) do |reference|
        $stderr.puts "      Determining if reference ##{reference[1]} meets criteria..."
        issue_id = reference[1].to_i
        if issue_has_label?(issue_id, flake_config['repo'], flake_config['label'])
          $stderr.puts "      Reference ##{reference[1]} points to a valid flake issue"
          return true
        end
      end

      return false
    end

    # issue_has_label? determines if the issue at the
    # repo and issue ID has a label with the given name
    def issue_has_label?(issue_id, repo, label_name)
      get_labels(issue_id, repo).each do |label|
        if label["name"] == label_name
          return true
        end
      end
      return false
    end

    # format_teams builds a list of links to team rosters from a list of team IDs
    def format_teams(team_ids)
      links = []
      team_ids.each do |id|
        url, name = team_url_and_name(id)
        links << "[#{name}](#{url})"
      end
      if links.length == 1
        "the #{links[0]} group"
      elsif links.length == 2
        "the #{links[0]} or #{links[1]} groups"
      else
        "the #{links[0..-1].join(", ")} or #{links[-1]} groups"
      end
    end

    # format_flake_comment builds a comment explaining why a re-build could not be triggered
    def format_flake_comment(prefix, flake_config, team_ids)
      flake_label = flake_config['label']
      flake_repo = flake_config['repo']
      org_repo = "#{Properties['github_user']}/#{flake_repo}"
      flake_label_query = CGI.escape("label:#{flake_label}")
      issue_link = "https://github.com/#{org_repo}/issues?q=#{flake_label_query}"
      new_issue_link = "https://github.com/#{org_repo}/issues/new"

      "
#{prefix}
 - If the proposed changes in this pull request caused the job to fail, update this pull request with new code to fix the issue(s).
 - If flaky tests caused the job to fail, leave a comment with links to the GitHub issue(s) in the `#{org_repo}` repository with the [`#{flake_label}` label](#{issue_link}) that are tracking the flakes. If no issue already exists for the flake you encountered, [create one](#{new_issue_link}).
 - If something else like CI system downtime or maintenance caused the job to fail, contact a member of #{format_teams(team_ids)} to trigger the job again.
      "
    end

    # format_flake_satisfaction_message builds a formatted message for logging that explains
    # why the flake identification criteria were satisfied
    def format_flake_satisfaction_message(explanatory_comment_valid, admin_trigger_valid, changed_after_eval)
      reasons = []
      reasons << "valid identification comment found" if explanatory_comment_valid
      reasons << "administrative trigger found" if admin_trigger_valid
      reasons << "new changes found" if changed_after_eval

      "  Flake identification satisfied: #{reasons.join(", ")}, resubmitting..."
    end

    #
    # Processes a specific pull request.  Manages the various comment
    # states and will submit tests as necessary and update the comment
    # with the results.  Tests will be resubmitted if the issue has
    # been updated since the test have been run
    #
    def process_pull_request(req, updated_at, changed_after_eval, comments, settings, merge_pretest_success)
      id = req['number']
      branch = req['base']['ref']
      base_repo = req['base']['repo']['name']
      login = req['user']['login']
      repo_to_pull_request = {base_repo => req}

      $stderr.puts "\n****Processing #{settings['name'].upcase} in '#{branch}' branch for user '#{login}' on: #{GITHUB_BASE_URL}/#{Properties['github_user']}/#{base_repo}/pull/#{id}"

      trigger_updated_at, trigger_login = get_trusted_trigger_time(req, comments, settings)

      evaluated_time = get_evaluated_time(comments, base_repo, settings)

      $stderr.puts "  Updated at: #{updated_at}"
      $stderr.puts "  Changed after evaluated time: #{changed_after_eval}"
      $stderr.puts "  Trigger updated at: #{trigger_updated_at}"
      $stderr.puts "  Evaluated time: #{evaluated_time}"

      # Gather any dependencies from trusted users and add them to the repo_to_pull_request mapping
      $repo_to_pull_regex.each do |repo, regex|
        next if repo == base_repo
        if req['body'] =~ regex
          addtl_pull_id = $2
          add_coreq(addtl_pull_id, repo, login, trigger_login, repo_to_pull_request, settings, trigger_updated_at, Time.parse(req['updated_at']), id, base_repo, comments)
        end
      end

      comments.each do |comment|
        $repo_to_pull_regex.each do |repo, regex|
          next if repo == base_repo
          if comment['body'] =~ regex
            addtl_pull_id = $2
            add_coreq(addtl_pull_id, repo, comment['user']['login'], trigger_login, repo_to_pull_request, settings, trigger_updated_at, Time.parse(comment['updated_at']), id, base_repo, comments)
          end
        end
      end

      updated_comment = nil
      status = nil
      build_url = nil
      # Find the bot comment for this pull request (or create one)
      process_or_create_comment(id, base_repo, settings, comments) do |comment_id, comment, comment_updated_at|
        submit_test_job = false
        resubmit_test_job = false

        # Given the last comment made by the bot, we can determine the state in which evaluation
        # of this pull request ended previously, depending on which we will take different actions
        case comment
        when /^#{settings['test_prefix']} Evaluating/
          # In this case, we have just made a placeholder comment as we have not seen this pull
          # request previously and are evaluating it for the first time. To move forward, we want
          # to ensure that all of the co-requisite pull requests have no updates more recent than
          # the most recent trigger we have seen.
          # TODO: we should *always* check this, above, not only in this state
          #
          # Two state transitions are possible out of this state:
          #  - into the 'waiting for stable build' phase, as we cannot move to begin a test unless
          #    the downstream jobs in Jenkins are ready to run them
          #  - into the 'running tests' phase, if we have a trusted trigger that covers all the
          #    commits in the main pull request and any co-requisites
          $stderr.puts "  Evaluating..."

          if JenkinsAPI.project_stable?(branch, settings)
            # Make sure there is a trigger in place that is still later than the updated dates of each of the pull requests
            if trigger_updated_at
              repo_to_pull_request.each do |repo, pull_request|
                next if repo == base_repo
                if !user_trusted?(pull_request['user']['login'], repo, settings) && trigger_updated_at < Time.parse(pull_request['head']['repo']['updated_at'])
                  create_or_update_comment(id, base_repo, ACTION_PREFIX, ACTION_NOT_TEAM, comments)
                  break
                end
              end
              # the main pull request and all of the co-requisite pull requests haven't been
              # updated since the last trusted trigger, so we can begin testing
              update_evaluated_markers(repo_to_pull_request, trigger_updated_at, settings)
              submit_test_job = true
            else
              # no trusted trigger statement has been made, so we cannot build or test this pull
              create_or_update_comment(id, base_repo, ACTION_PREFIX, ACTION_NOT_TEAM, comments)
            end
          else
            updated_comment = "#{settings['test_prefix']} Waiting for stable build of '#{branch_settings(branch, settings)['downstream_job_name']}'"
          end

        when /^#{settings['test_prefix']} Waiting/
          # In this case, we are in one of two states:
          #  1) waiting for a downstream project in Jenkins to be stable, so we can begin tests
          #  2) waiting in a queue to begin tests
          #
          # Two state transitions are possible from state 1):
          #  - loop back into state 1) if the Jenkins project is unstable
          #  - into the 'running tests' state if the Jenkins project is stable
          # If the main pull request or any of the co-requisites have been
          # updated since the last time we evaluated the main pull request, we need to re-queue the
          # build and test.
          #
          # No state transitions occur from state 2)
          # TODO: currently, we have two invalid states that will make it through this logic: the
          # cases where we are not in the build queue but have submitted tests, and the cases where
          # we are in the build queue but have not submitted tests. Neither of these cases are valid
          # and we need to reconsider why they're tolerated
          $stderr.puts "  Waiting..."
          # Only submit the tests if the project is stable
          if JenkinsAPI.project_stable?(branch, settings)
            submitted_tests = submitted_tests_for_branch(branch)
            if !(submitted_tests[settings['name']] && comment =~ /^#{settings['test_prefix']} Waiting: You are in the build queue at position: \d+/)
              $stderr.puts "  Checking that evaluated times are still up to date"
              if changed_after_eval
                resubmit_test_job = true
              else
                submit_test_job = true
                repo_to_pull_request.each do |repo, sub_pull_request|
                  next if repo == base_repo
                  $stderr.puts "  Checking evaluated time for sub pull request #{sub_pull_request['number']} for repo '#{repo}'"
                  sub_pull_comments = get_comments(sub_pull_request['number'], repo)
                  sub_pull_request_updated_at, sub_pull_request_changed_after_eval = get_updated_at(sub_pull_request, sub_pull_comments, settings)

                  $stderr.puts "  Updated at: #{sub_pull_request_updated_at}"
                  $stderr.puts "  Changed after evaluated time: #{sub_pull_request_changed_after_eval}"
                  if sub_pull_request_changed_after_eval
                    resubmit_test_job = true
                    break
                  end
                end
              end
            else
              $stderr.puts "  Job is already queued"
            end
          end
        when /^#{settings['test_prefix']} Running \(([^\)]+)\)( \(Extended Tests: [^\)]+\).*)?/
          # In this state, we have triggered tests and made it through the build queue, so there
          # are running tests
          #
          # There are two state transitions possible from this state:
          #  - loop back into this state if the tests are still running
          #  - into the appropriate post-build state, of which I know of:
          #    - SUCCESS
          #    - ABORTED
          #    - UNSTABLE
          #    - NOTFOUND

          # Capture the build_url from the regex match
          build_url = $1
          extended_tests = $2
          $stderr.puts "  Running: #{build_url}consoleFull"

          # If the build is finished, update with the results
          if JenkinsAPI.build_running?(build_url, branch, settings)
            submitted_tests = submitted_tests_for_branch(branch)
            submitted_tests[settings['name']] = true unless settings['allow_multiple']
          else
            result = JenkinsAPI.build_result(build_url, branch, settings)
            updated_comment = "#{settings['test_prefix']} #{result} (#{build_url})"
            updated_comment += extended_tests if extended_tests
            status = result == 'SUCCESS' ? 'success' : 'failure'
          end
        when /^#{settings['test_prefix']} FAILURE \(([^\)]*)\)?/
          # In this case, are in the post-test result state, and the tests have failed
          #
          # The two states that we can transition to from here are:
          #  - loop back into this state if:
          #      - flake enforcement is configured and
          #      - there is no comment linking a valid flake issue to the last failed
          #        job and
          #      - the is no administrative trigger, overriding the check and
          #      - the base branch of the pull request has not been updated from the
          #        version used to run the tests previous ly
          #  - into the testing state if either:
          #      - flake enforcement is not configured, or
          #      - a contributor has linked the failure to a flake issue, or
          #      - an administrator has overriden the check, or
          #      - new code has been pushed to the branch since the last time this bot
          #        evaluated the pull request
          $stderr.puts "  Job failed: #{comment}"

          flake_config = settings['flake_identification']
          if !flake_config
            # If no flake configuration exists, it's ok to re-submit the job whenever
            # a new trigger is added to the pull request
            $stderr.puts "  No flake identification configuration exists, resubmitting..."
            resubmit_test_job = true
          else
            # If flake configuration does exist, we have to determine if we are OK to
            # re-submit or not

            # We can capture the URL of the failed build from the regex match
            build_url=$1
            $stderr.puts "  Determining if flakes have been identified for failed job: #{build_url}"

            admin_trigger_updated_at, _ = get_admin_trigger_time(req, comments, settings)
            admin_trigger_valid = admin_trigger_updated_at && admin_trigger_updated_at > updated_at
            if !admin_trigger_valid && !changed_after_eval
              # if there is nothing else that is going to re-trigger this job, we
              # look to find an explanatory comment. This is a costly process in
              # terms of API calls, so we only do it if we need to.
              explanatory_comment_valid = has_valid_flake_comment?(comments_after(comments, comment_updated_at), flake_config)
            else
              explanatory_comment_valid = false
            end

            flake_comment_prefix = flake_denied_prefix(base_repo, settings['name'])
            flake_comment_body = format_flake_comment(flake_comment_prefix, flake_config, settings['repo_to_admin_teams'][base_repo])

            # If we can find an explanatory comment with a valid flake issue in it,
            # or we find an admin override comment, or the pull request has had new
            # code added to it since the last evaluation, we know that we are good
            # to resubmit the pull request for testing
            if explanatory_comment_valid || admin_trigger_valid || changed_after_eval
              $stderr.puts format_flake_satisfaction_message(explanatory_comment_valid, admin_trigger_valid, changed_after_eval)
              resubmit_test_job = true
              delete_comment_with_prefix(id, base_repo, flake_comment_prefix, comments)
            else
              $stderr.puts "  Flake identification not satisfied"
              if trigger_updated_at && trigger_updated_at > evaluated_time
                # If someone's tried to trigger a re-test, but we can't re-test right
                # now, we should leave a helpful message explaining why. If we have
                # previously warned the user about why we couldn't re-test, we should
                # only update the pull request with a new set of reasons if the trigger
                # is newer than our last comment
                previous_warning = get_comment_with_prefix(id, base_repo, flake_comment_prefix, comments)
                if !previous_warning || (previous_warning && trigger_updated_at > Time.parse(previous_warning['updated_at']))
                  $stderr.puts "    New reminder comment is appropriate for this pull request"
                  recreate_comment_with_prefix(id, base_repo, flake_comment_prefix, flake_comment_body, comments)
                end
              end
            end
          end
        else
          # In this case, we're in one of three states:
          #  1) ACTION_NOT_MERGE: the pull request is not mergeable and needs a rebase
          #  2) ACTION_NOT_TEAM: the pull request has no trusted triggers
          #  3) the build has finished, with one of the following states:
          #    - SUCCESS
          #    - ABORTED
          #    - UNSTABLE
          #    - NOTFOUND
          #
          # Regardless of the current state, since we have a trusted trigger, we want to
          # re-submit this pull request for testing.
          $stderr.puts "  Finished..."
          $stderr.puts "  #{comment}" if comment =~ /^#{settings['test_prefix']} .+ \([^\)]+\)/
          resubmit_test_job = true
        end

        # Once we have considered the current state of the pull request, we need to determine
        # if we are going to submit this pull request for testing
        if resubmit_test_job
          # If analysis of the current state has determined that we should re-submit the job
          # for testing, we need to check that we meet all criteria for resubmission:
          #  - is the project stable? [TODO: we seem to be checking this always, move up?]
          #  - have there been any changes in the main pull request since the last evaluation?
          #  - have there been any changes in the co-requisite pull requests since the last evaluation?
          #
          # TODO: this logic has bled out and should be moved into a function that is called
          # inside of each state case above, instead of being called this way. Ideally each
          # state case above should be able to either submit or not submit tests internally.
          submit_test_job = false

          $stderr.puts "  Checking whether we should resubmit"
          if trigger_updated_at
            # We already trust the primary pull request.  Just need to check whether the eval time is older than last update or last trusted trigger.
            if changed_after_eval || (evaluated_time < trigger_updated_at)
              if JenkinsAPI.project_stable?(branch, settings)
                submit_test_job = true
              else
                updated_comment = "#{settings['test_prefix']} Waiting for stable build of '#{branch_settings(branch, settings)['downstream_job_name']}'"
              end
            end

            # Check for any other reason to submit the test job.  And make sure non of the sub pull requests have new untrusted changes.
            repo_to_pull_request.each do |repo, sub_pull_request|
              next if repo == base_repo

              $stderr.puts "  Checking evaluated time for sub pull request #{sub_pull_request['number']} for repo '#{repo}'"
              sub_pull_comments = get_comments(sub_pull_request['number'], repo)
              sub_pull_request_updated_at, sub_pull_request_changed_after_eval = get_updated_at(sub_pull_request, sub_pull_comments, settings)

              $stderr.puts "  Updated at: #{sub_pull_request_updated_at}"
              $stderr.puts "  Changed after evaluated time: #{sub_pull_request_changed_after_eval}"

              # Make sure the trigger on the primary pull request is after the updated date of the sub pull request
              # or the user of the sub pull request is trusted
              valid_trigger_comment = trigger_updated_at > sub_pull_request_updated_at
              $stderr.puts "  Has valid trigger comment: #{valid_trigger_comment}"
              if valid_trigger_comment || user_trusted?(sub_pull_request['user']['login'], repo, settings)
                if sub_pull_request_changed_after_eval
                  if JenkinsAPI.project_stable?(branch, settings)
                    submit_test_job = true
                  else
                    updated_comment = "#{settings['test_prefix']} Waiting for stable build of '#{branch_settings(branch, settings)['downstream_job_name']}'"
                  end
                end
              else
                create_or_update_comment(id, base_repo, ACTION_PREFIX, ACTION_NOT_TEAM, comments)
                submit_test_job = false
                break
              end
            end
          else
            create_or_update_comment(id, base_repo, ACTION_PREFIX, ACTION_NOT_TEAM, comments)
            submit_test_job = false
          end
          if submit_test_job
            update_evaluated_markers(repo_to_pull_request, trigger_updated_at, settings)
          end
        end

        # To complete the transition into the next phase of the pull request evaluation,
        # we need to take the correct external actions if necessary and update the bot
        # comment to reflect the new state
        if submit_test_job
          delete_comment_with_prefix(id, base_repo, ACTION_PREFIX, comments)
          extended_tests = get_extended_tests(req, comments, branch, settings)
          submit_tests(repo_to_pull_request, base_repo, branch, id, comment_id, extended_tests, settings)
        elsif updated_comment
          # If we have an `updated_comment`, we have determined which state we want to
          # transition into above literally and simply need to update the comment to
          # reflect that
          recreate_comment(id, comment_id, base_repo, updated_comment)
          repo_to_pull_request.each do |repo, pull_request|
            if status && build_url
              # One of the literal transitions we specify is the transition from running
              # tests to reporting the results, so if a result has been specified we
              # furthermore know that we are transitiong into the post-test state and can
              # update the GitHub pull request status
              commit = get_last_commit(pull_request['number'], repo)
              update_status(settings['test_prefix'], commit['sha'], repo, status, build_url, (status == 'success') ? 'Passed' : 'Failed')
            end
            next if repo == base_repo
            recreate_comment_with_prefix(pull_request['number'], repo, settings['test_prefix'], updated_comment)
          end
        else
          # If we are not running tests and have not specified a literal state to transition
          # into, we have one more transition to check: from post-build sucess to merge
          Properties['settings'].each_value do |s|
            if s['pretest_settings_key'] && merge_pretest_success
              if Properties['settings'][s['pretest_settings_key']]['name'] == settings['name']
                if comment =~ /^#{settings['test_prefix']} SUCCESS \(([^\)]+)\)/
                  build_url = $1
                  trusted_trigger_time, trigger_login = get_trusted_trigger_time(req, comments, s)
                  if trusted_trigger_time
                    begin
                      repo_to_pull_request.each do |repo, pull_request|
                        test_merge_pull_request(pull_request['number'], repo, s)
                      end if repo_to_pull_request.length > 0
                      repo_to_pull_request.each do |repo, pull_request|
                        $stderr.puts "\n*******Merging pretested pull request: #{GITHUB_BASE_URL}/#{Properties['github_user']}/#{repo}/pull/#{pull_request['number']} "
                        merge_pull_request(pull_request['number'], repo, s, build_url)
                      end
                    rescue Exception => e
                      $stderr.puts e.message
                      $stderr.puts e.backtrace
                    end
                  end
                end
                break
              end
            end
          end
        end
      end

    end

    # The GitHub mergeable API is flaky, so we use an external file ``database'' to record
    # pull request mergeability responses with a biased saturating counter so that pull
    # request comment/label actions are only taken after a critical amount of net positive
    # or negative API responses. However, a pull request is immediately chosen not to be
    # tested after the first unmergeable result, even if it takes longer for the UX comment
    # and label to be applied.
    #
    # The saturation points are at 0 and 10, with an initial state of 0, so i.e. the default
    # state is to consider the pull request mergeable, and this state will not change until
    # a net of ten unmergeable responses come in from the GitHub API. When set_mergeable is
    # called, the counter for the specific pull ID is decremented if it hasn't saturated;
    # when set_not_mergeable is called, the counter is incremented unless it is saturated.

    # set_mergeable updates the pull request at repo/pull/id to remove labels and comments
    # that indicate a rebase is necessary. The update happens when the counter described
    # above is saturated at 0.
    def set_mergeable(id, repo, login, comments=nil)
      merge_id="#{repo}_#{id}_#{login}"
      count = MERGEABLE
      previous_merge_result=`grep #{merge_id} ~/test_pull_request_not_mergeable`.chomp
      if !previous_merge_result.empty? && previous_merge_result =~ /#{merge_id}=(\d+)/
        count = $1.to_i
      end
      if count <= MERGEABLE
        # If our counter has saturated at 0, we want to remove any comments and labels about
        # rebasing as this pull request is mergeable
        `sed -i "/#{merge_id}=/d" ~/test_pull_request_not_mergeable`
        comments = get_comments(id, repo) if comments.nil?

        # In the majority of cases, we have all of the comments for a pull request, so we can
        # look to see if an ACTION_NOT_MERGE comment exists with zero additional API traffic.
        # If we find an ACTION_NOT_MERGE comment, we remove it, and furthermore we know we should
        # also delete the NEEDS_REBASE_LABEL. If we didn't remove the comment (because it didn't
        # exist, or because we failed through the API), we want to try to remove the label
        # anyway to ensure that the UX for PRs is good. Since we do *not* have the labels for
        # a PR, this is a costly operation, so we do not attempt to do it always, only when we
        # know for sure we need to, or once in a while randomly.
        if delete_comment_with_prefix(id, repo, ACTION_NOT_MERGE, comments) || (rand(5) < 1)
          remove_labels(id, repo, [NEEDS_REBASE_LABEL])
        end
      else
        # if our counter is not saturated, we pull it towards 0
        `sed -i "/#{merge_id}=/d" ~/test_pull_request_not_mergeable && echo "#{merge_id}=#{(count-1).to_s}" >> ~/test_pull_request_not_mergeable`
      end
    end

    # set_not_mergeable updates the pull request at repo/pulls/id to add a comment and label
    # that informs the author that a rebase is necessary to merge the pull request. The update
    # happens when the counter described above is saturated at 10. set_not_mergeable will return
    # the value of the current counter.
    def set_not_mergeable(id, repo, login)
      merge_id="#{repo}_#{id}_#{login}"
      count = MERGEABLE
      previous_merge_result=`grep #{merge_id} ~/test_pull_request_not_mergeable`.chomp
      if !previous_merge_result.empty? && previous_merge_result =~ /#{merge_id}=(\d+)/
        count = $1.to_i
      end
      if count >= NOT_MERGEABLE
        # If our counter is saturated at 10, we want to add the comment and label
        create_or_update_comment(id, repo, ACTION_PREFIX, ACTION_NOT_MERGE)
        ensure_labels(id, repo, [NEEDS_REBASE_LABEL])
      else
        # If our counter is not saturated, we pull it towards 10
        `sed -i "/#{merge_id}=/d" ~/test_pull_request_not_mergeable && echo "#{merge_id}=#{(count+1).to_s}" >> ~/test_pull_request_not_mergeable`
      end
      # return the previous value of the saturating counter so callers can consume it to
      # determine stability level
      count
    end

    #
    # Processes a list of the valid pull requests that are mergeable
    # and are submitted by a trusted user
    #
    def process_pull_requests(merge_pretest_success)
      pull_requests = []
      mergeability_in_flux = false
      $repo_to_pull_regex.keys.each do |repo|
        $stderr.puts "\nProcessing repo '#{repo}'"
        list_pull_requests(repo).each do |req|
          id = req['number']
          $stderr.puts "Analyzing pull request: #{GITHUB_BASE_URL}/#{Properties['github_user']}/#{repo}/pull/#{id}"

          branch = req['base']['ref']

          # We only want to consider pull requests into branches we care about
          if $branches.include?(branch) || $branches.include?('*')

            $stderr.puts "  Updated at: #{req['updated_at']}"
            # We only want to consider pull requests that have been modified in
            # the last twelve hours, to stop us from doing extra work when we
            # don't need to. Also, just to ensure that we don't forget a pull
            # request forever on accident, there is a 10% chance we'll consider
            # a pull request even if it is inactive
            if Time.now - Time.parse(req['updated_at']) < (12*60*60) || (rand(20) < 1)
              login = req['user']['login']
              comments = nil
              # Skip if it's not mergeable
              mergeable = is_mergeable?(id, repo)
              $stderr.puts "  Mergeable: #{mergeable}"
              if mergeable
                comments = get_comments(id, repo) if comments.nil?
                set_mergeable(id, repo, login, comments)
              else
                if set_not_mergeable(id, repo, login) == MERGEABLE
                  mergeability_in_flux = true
                end
                next
              end

              comments = get_comments(id, repo) if comments.nil?

              # We only want to consider pull requests where the last trigger we found
              # is from a trusted user
              permission_denied = Array.new(Properties['settings'].length, false)
              # Has a merge or test been requested by a trusted user?
              Properties['settings'].values.each_with_index do |settings, i|
                updated_at, changed_after_eval = get_updated_at(req, comments, settings)
                trigger_regex = /\[#{settings['name']}\]/i
                if req['title'] =~ trigger_regex || req['body'] =~ trigger_regex
                  if user_trusted?(login, repo, settings)
                    pull_requests << [req, updated_at, changed_after_eval, comments, settings]
                    permission_denied[i] = false
                    next
                  else
                    $stderr.puts "  User '#{login}' not trusted"
                    permission_denied[i] = true
                  end
                end

                comments = sort_comments(comments)
                comments.each do |comment|
                  if comment['body'] =~ trigger_regex
                    comment_login = comment['user']['login']
                    if user_trusted?(comment_login, repo, settings)
                      pull_requests << [req, updated_at, changed_after_eval, comments, settings]
                      permission_denied[i] = false
                      break
                    else
                      $stderr.puts "  User '#{comment_login}' not trusted"
                      permission_denied[i] = true
                    end
                  end
                end
              end
              if permission_denied.include? true
                create_or_update_comment(id, repo, ACTION_PREFIX, ACTION_NOT_TEAM, comments)
              end
            else
              $stderr.puts "  Skipping due to age and inactivity"
            end
          else
            create_or_update_comment(id, repo, ACTION_PREFIX, ACTION_UNSUPPORTED_BRANCH)
          end
        end
      end

      if mergeability_in_flux
        $stderr.puts "Waiting till next run to see if mergeability is in flux"
        exit
      end

      # Consider the pull requests we have deemed valid in
      # order of the time they were last updated, oldest first
      sorted_pull_requests = pull_requests.sort_by do |req_info|
        req_info[1]
      end

      skipped_count = {}
      $branches.each do |branch|
        skipped_count[branch] = {}
      end

      # If we're only allowing sequential tests in this tag, we want to find
      # any pull request in the 'running tests' state and signal that there
      # is a test running.
      sorted_pull_requests.each do |req_info|
        req = req_info[0]
        comments = req_info[3]
        settings = req_info[4]
        branch = req['base']['ref']

        if !settings['allow_multiple']
          comments.each do |comment|
            if (comment['user']['login'] == Properties['bot_github_user']) && (comment['body'] =~ /^#{settings['test_prefix']} Running \(([^\)]+)\)/)
              submitted_tests = submitted_tests_for_branch(branch)
              submitted_tests[settings['name']] = true
              break
            end
          end
        end
      end

      sorted_pull_requests.each do |req_info|
        # Process the pull request
        req = req_info[0]
        updated_at = req_info[1]
        changed_after_eval = req_info[2]
        comments = req_info[3]
        settings = req_info[4]
        branch = req['base']['ref']

        process_pull_request(req, updated_at, changed_after_eval, comments, settings, merge_pretest_success)

        submitted_tests = submitted_tests_for_branch(branch)

        if !settings['allow_multiple'] && submitted_tests[settings['name']]
          # If we're only allowing sequential tests on this tag and there is a test running,
          # and we are waiting to test, we need to correctly determine the position in the
          # test queue that we are at and post it in a bot comment on the pull request
          comments = get_comments(req['number'], req['base']['repo']['name'])

          bot_comment = get_comment_with_prefix(req['number'], req['base']['repo']['name'], settings['test_prefix'], comments)
          if bot_comment && (bot_comment['body'] =~ /^#{settings['test_prefix']} Waiting/)
            skipped_count_branch = skipped_count[branch] ? skipped_count[branch] : skipped_count['*']
            skipped_count_branch[settings['name']] = 0 if skipped_count_branch[settings['name']].nil?
            skipped_count_branch[settings['name']] += 1
            queued_comment = "#{settings['test_prefix']} Waiting: You are in the build queue at position: #{skipped_count_branch[settings['name']].to_s}"
            create_or_update_comment(req['number'], req['base']['repo']['name'], settings['test_prefix'], queued_comment , comments)
            $stderr.puts "  Pull ##{req['number']} in repo '#{req['base']['repo']['name']}' is at build position ##{skipped_count_branch[settings['name']]}"
            # Get ahead of the game and pretest requests
            if settings['pretest_settings_key'] && settings['pretest_comment'] && settings['pretest_queue_threshold'] && (skipped_count_branch[settings['name']] >= settings['pretest_queue_threshold'])
              trusted_trigger_time, _ = get_trusted_trigger_time(req, comments, Properties['settings'][settings['pretest_settings_key']])
              create_or_update_comment(req['number'], req['base']['repo']['name'], settings['pretest_comment'].gsub('[', '\[').gsub(']', '\]'), settings['pretest_comment'], comments) unless trusted_trigger_time
            end
          end
        end
      end
    end
  end

  #
  # A class to encapsulate the Jenkins API interaction
  #
  class JenkinsAPI

    def self.submit_jenkins_job(repo_to_pull_request, branch, extended_tests, settings)
      # First, get the next jenkins build number
      next_build_num = get_next_build(branch, settings)

      pull_id_params = "&BRANCH=#{branch}"
      first_valid_repo = nil
      repo_to_pull_request.each do |repo, pull_request|
        pull_id_param = settings['repo_to_pull_id_param'][repo]
        if pull_id_param
          pull_id_params += "&#{pull_id_param}=#{pull_request['number']}"
          first_valid_repo = repo unless first_valid_repo
        end
      end

      extended_tests_param = branch_settings(branch, settings)['extended_tests_param']
      if !extended_tests.empty? && extended_tests_param
        pull_id_params += "&#{extended_tests_param}=#{extended_tests.join(',')}"
      end

      if first_valid_repo
        addtl_jenkins_params = branch_settings(branch, settings)['addtl_jenkins_params']
        addtl_jenkins_params[Properties['repo_groups'][first_valid_repo]].each do |key, value|
          value = replace_wildcard(value, branch)
          pull_id_params += "&#{key}=#{value}"
        end if addtl_jenkins_params
      end

      build_uri = URI(URI.escape(Properties['jenkins_url'] + 'job/' + branch_settings(branch, settings)['jenkins_job_name'] + "/buildWithParameters?token=#{branch_settings(branch, settings)['build_token']}#{pull_id_params}"))

      # Now submit the Jenkins job
      get_session(branch, settings).start do |http|
        response = http_get(http, build_uri)
        if (response.kind_of? Net::HTTPFound) || (response.kind_of? Net::HTTPCreated)
          $stderr.puts "  Successfully submitted job for pull request"

          # Block until Jenkins actually increments the build number (this isn't transactional)
          $stderr.puts "  Now waiting until build number increments..."
          tries = 1
          while true
            begin
              while get_next_build(branch, settings) == next_build_num
                sleep 1
              end
              break
            rescue
              raise if tries >= 3
              tries += 1
            end
          end

          # Now you can safely return with the submission registered
          return Properties['jenkins_url'] + 'job/' + branch_settings(branch, settings)['jenkins_job_name'] + "/#{next_build_num}/"
        else
          raise "Jenkins job submission failed for pull request"
        end
      end
    end

    def self.project_stable?(branch, settings)
      if branch_settings(branch, settings)['downstream_job_name'] && branch_settings(branch, settings)['require_downstream_stability']
        get_session(branch, settings).start do |http|
          url = downstream_job_url(branch, settings)
          response = http_get(http, url)
          if response.kind_of? Net::HTTPSuccess
            result = JSON.parse(response.body)["result"]
            return  result == "SUCCESS" || result == "UNSTABLE"
          else
            raise "Jenkins connection error"
          end
        end
      else
        return true
      end
    end

    def self.get_next_build(branch, settings, job_name=nil)
      job_name = job_name ? job_name : branch_settings(branch, settings)['jenkins_job_name']
      job_api_url = "#{Properties['jenkins_url']}job/#{job_name}"
      get_session(branch, settings).start do |http|
        response = http_get(http, job_api_url)
        if response.kind_of? Net::HTTPSuccess
          JSON.parse(response.body)["nextBuildNumber"].to_i
        else
          raise "Jenkins connection error"
        end
      end
    end

    def self.previous_build_running?(branch, settings, repo)
      $stderr.puts "  Checking for existing build of the same type running in Jenkins"
      addtl_jenkins_params = branch_settings(branch, settings)['addtl_jenkins_params']
      previous_running = false
      get_session(branch, settings).start do |http|
        build_uri = URI(Properties['jenkins_url'] + 'job/' + branch_settings(branch, settings)['jenkins_job_name'] + '/api/json?tree=builds[building,actions[parameters[name,value]]]')
        response = http_get(http, build_uri)
        if response.kind_of? Net::HTTPSuccess
          output = JSON.parse(response.body)
          output['builds'].each do |build|
            previous_running = build['building']
            if previous_running
              actions = build['actions']
              submitted_params = nil
              actions.each do |action|
                if action['_class'] == 'hudson.model.ParametersAction'
                  submitted_params = action['parameters']
                  break
                end
              end
              # Validate that the params match between the test settings and jenkins for cases that the same job is being used for multiple test commands
              if submitted_params && addtl_jenkins_params && addtl_jenkins_params[Properties['repo_groups'][repo]]
                previous_running = submitted_params_match?(submitted_params, addtl_jenkins_params[Properties['repo_groups'][repo]], branch)
              end
              # Exit if you found a match.  Otherwise keep looking.
              break if previous_running
            end
          end
        elsif response.kind_of? Net::HTTPNotFound
          raise "Jenkins status url not found: #{build_uri.request_uri}"
        else
          raise "Jenkins status url returned an invalid result: #{build_uri.request_uri}"
        end
      end
      return previous_running
    end

    def self.build_running?(build_url, branch, settings)
      get_session(branch, settings).start do |http|
        response = http_get(http, build_url)
        if response.kind_of? Net::HTTPSuccess
          return JSON.parse(response.body)["building"]
        elsif response.kind_of? Net::HTTPNotFound
          return false
        else
          raise "Jenkins connection error"
        end
      end
    end

    def self.build_result(build_url, branch, settings)
      get_session(branch, settings).start do |http|
        response = http_get(http, build_url)
        if response.kind_of? Net::HTTPSuccess
          build = JSON.parse(response.body)
          return build["result"]
        elsif response.kind_of? Net::HTTPNotFound
          return "NOTFOUND"
        else
          raise "Jenkins connection error"
        end
      end
    end

    private

    def self.submitted_params_match?(submitted_params, test_params, branch)
      submitted_param_map = {}
      submitted_params.each do |param|
        submitted_param_map[param['name']] = param['value']
      end
      test_params.each do |key, value|
        value = replace_wildcard(value, branch)
        submitted_value = submitted_param_map[key]
        if !submitted_value.nil? && submitted_value != value
          $stderr.puts "    #{submitted_value} != #{value} for '#{key}' param"
          return false
        end
      end
      return true
    end

    def self.http_get(http, uri)
      uri = to_api_uri(uri) if uri.is_a? String
      request = Net::HTTP::Get.new uri.request_uri
      http.request request
    end

    def self.replace_wildcard(s, replacement)
      s = s.gsub('*', replacement) if s.is_a? String
      s
    end

    def self.to_api_uri url
      URI(url + "/api/json")
    end

    def self.downstream_job_url(branch, settings)
      job_name = branch_settings(branch, settings)['downstream_job_name']
      "#{Properties['jenkins_url']}job/#{job_name}/lastCompletedBuild"
    end

    def self.job_url(branch, settings)
      job_name = branch_settings(branch, settings)['jenkins_job_name']
      "#{Properties['jenkins_url']}job/#{job_name}/lastCompletedBuild/"
    end

    def self.get_session(branch, settings)
      proxy = Net::HTTP::Proxy(Properties['proxy_host'], Properties['proxy_port'])
      url = nil
      if branch_settings(branch, settings)['downstream_job_name']
        url = downstream_job_url(branch, settings)
      else
        url = job_url(branch, settings)
      end
      uri = to_api_uri(url)
      session = proxy.new(uri.host, uri.port)
      session.use_ssl = true
      session.verify_mode = OpenSSL::SSL::VERIFY_NONE
      return session
    end

  end
end

#
#
# The main program script
#
#

# Create a new Hub client
@api_client ||= begin
  config_file = ENV['HUB_CONFIG'] || Properties['hub_config']
  file_store = GitHubAPI::FileStore.new File.expand_path(config_file)
  file_config = GitHubAPI::Configuration.new file_store
  GitHubAPI.new file_config, :app_url => Properties['jenkins_host']
end

if merge_pull_id
  @api_client.merge_pull_request(merge_pull_id, pull_id_repo, Properties['settings']['merge_test_settings'])
elsif mark_test_success_pull_id
  @api_client.mark_test_success(mark_test_success_pull_id, pull_id_repo, Properties['settings']['test_settings'])
elsif mark_testonlyextended_success_pull_id
  @api_client.mark_test_success(mark_testonlyextended_success_pull_id, pull_id_repo, Properties['settings']['testonlyextended_settings'])
elsif local_merge_pull_id
  @api_client.local_merge_pull_request(local_merge_pull_id, pull_id_repo)
elsif test_merge_pull_id
  @api_client.test_merge_pull_request(test_merge_pull_id, pull_id_repo, Properties['settings']['merge_test_settings'])
else
  # Process all the pull requests for testing
  $stderr.puts "Processing pull requests..."
  @api_client.process_pull_requests(merge_pretest_success)
  $stderr.puts "\nDone\n"
end

